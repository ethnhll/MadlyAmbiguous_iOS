MadlyAmbiguous
==============

Our goal is to create an iOS application that demonstrates the difficulty of disambiguating/paraphrasing language in an entertaining and simple to understand way. A particular challenge to this project is in establishing effective "off-line" methods of disambiguating arbitrary input from a user. This is not a trivial task as we are limited by hard drive space on the iPad and as such, we have limited the input a user may enter to specific examples that demonstrate classic ambiguities in English. 
=================



NOTES
=================

Attachment Ambiguity

Prepositional Phrase Attachment

In our example sentence, I ate spaghetti with BLANK, the user can replace BLANK with an arbitrary phrase. Our attempt then is to make use of Google Syntactic N-Gram data (link below, specifically the Arc data is being used). Using a simple bash script, each arc file is downloaded individually and then grep'd for the keyword combinations "spaghetti with" or "ate with" (obviously the combinations don't look like this but here they do for brevity) before being written to a reduced file ready for our purposes.

http://commondatastorage.googleapis.com/books/syntactic-ngrams/index.html

Our application then uses this file to calculate a conditional probability of a phrase entered by the user given either "spaghetti with" or "ate with." The phrase with the higher conditional probability is the attachment that is selected. 

A complication with this approach is that the user can enter more than just a single word, making the look-up of the phrase in the reduced N-Gram data much more complicated. To overcome this, we must determine what the head noun of the phrase entered by the user is. My approach was this: find a collection of *English's most common words** (links below) that are non-nouns and then, given input from the user, find the first word that is not found in this list and assume that it is the head-noun. This noun is then used to calculate conditional probabilities as before. Again, another complication arises in the case of compound but seperate nouns (for example the words book publisher or fire hydrant). It has been deemed best to ignore this case for now as it only complicates the solution unnecessarily given the scope of the application.

http://ucrel.lancs.ac.uk/bncfreq/lists/5_2_all_rank_verb.txt
http://ucrel.lancs.ac.uk/bncfreq/lists/5_3_all_rank_adjective.txt
http://ucrel.lancs.ac.uk/bncfreq/lists/5_4_all_rank_adverb.txt
http://ucrel.lancs.ac.uk/bncfreq/lists/5_6_all_rank_determ.txt
http://ucrel.lancs.ac.uk/bncfreq/lists/5_7_all_rank_detpro.txt
http://ucrel.lancs.ac.uk/bncfreq/lists/5_8_all_rank_preposition.txt
http://ucrel.lancs.ac.uk/bncfreq/lists/5_9_all_rank_conjunction.txt
http://ucrel.lancs.ac.uk/bncfreq/lists/5_10_all_rank_interjection.txt

*it should be noted that these common words are from written British English, though the most common words should not differ too greatly from written American English. I also removed the frequency counts from the aggregate file of the most frequent words in order to save space (the frequencies are not used at all for your purposes).

==================================

Structural Ambiguity

To illustrate this particular type of ambiguity, I chose the example sentence, "the pretty BLANK1 and BLANK2 were a sight to see," where BLANK's are replaced with nouns entered by the user. Here, our initial solution was to use a simple look-up of bigram data (link below) for "pretty BLANK1" and "pretty BLANK2" to see which bigram was more frequent. However, since Google N-Gram data is reflective of language use and not necssarily what is correct, simply selecting the more frequent bigram to resolve the ambiguity does not always result in the correct disambiguation. To overcome this, we introduce a scaling cutoff, where, if the greater conditional probability is less than 10 times greater than the lesser probability, the probabilities are to be considered equally likely. This then means that pretty attaches to both BLANK1 and BLANK2. Otherwise, pretty will attach to BLANK1.

http://storage.googleapis.com/books/ngrams/books/datasetsv2.html


The Bigram data was simply grep'd for the word pretty while other extraneous information was cut away (such as non-words that were paired with pretty).




